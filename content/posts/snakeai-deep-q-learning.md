---
title: "YÄ±lan Oyunu ve Yapay Zeka: Deep Q-Learning ile Kendi Kendine Ã–ÄŸrenen Ajan"
date: 2026-02-07T18:00:00+03:00
draft: false
tags: ["Python", "Artificial Intelligence", "Deep Learning", "SnakeAI", "PyTorch"]
categories: ["Tech", "AI", "Machine Learning"]
author: "Turgut ÅimÅŸek"
---

Merhaba! BugÃ¼n sizlerle, klasik **Snake (YÄ±lan)** oyununu bir yapay zekanÄ±n nasÄ±l en verimli ÅŸekilde oynayabileceÄŸini keÅŸfettiÄŸim projemi paylaÅŸmak istiyorum. Bu proje sadece bir oyun botu deÄŸil, aslÄ±nda modern yapay zekanÄ±n temellerinden biri olan **PekiÅŸtirmeli Ã–ÄŸrenme (Reinforcement Learning)** dÃ¼nyasÄ±na atÄ±lmÄ±ÅŸ ciddi bir adÄ±mdÄ±r.

![Snake AI Learning Process](/pic/snake_ai.gif)

### ğŸ§  Deep Q-Learning (DQN) Derinlemesine Ä°nceleme

Bu projede ajanÄ±n (yÄ±lanÄ±n) beyni olarak **Deep Q-Learning (DQN)** algoritmasÄ±nÄ± kullandÄ±m. Geleneksel Q-Learning'den farklÄ± olarak DQN, durum-aksiyon iliÅŸkilerini bir tablo yerine **Yapay Sinir AÄŸlarÄ± (Neural Networks)** kullanarak Ã¶ÄŸrenir.

#### 1. AjanÄ±n AlgÄ± DÃ¼nyasÄ± (State)
YÄ±lan, dÃ¼nyayÄ± 11 farklÄ± parametre Ã¼zerinden algÄ±lÄ±yor. Bu veriler sinir aÄŸÄ±mÄ±za girdi (input) olarak iletiliyor:
- **Tehlike AlgÄ±sÄ± (3 bit):** Tam Ã¶nÃ¼nde, saÄŸÄ±nda veya solunda bir engel (kendi kuyruÄŸu veya duvar) var mÄ±?
- **Hareket YÃ¶nÃ¼ (4 bit):** Åu an hangi yÃ¶ne (Sol, SaÄŸ, YukarÄ±, AÅŸaÄŸÄ±) gidiyor?
- **Yemek YÃ¶nÃ¼ (4 bit):** Yemek yÄ±lana gÃ¶re tam olarak nerede (Kuzey, GÃ¼ney, DoÄŸu, BatÄ±)?

#### 2. Sinir AÄŸÄ± Mimarisi
AjanÄ±n kararlarÄ±nÄ± veren sinir aÄŸÄ±, **PyTorch** ile inÅŸa edildi:
- **Input Layer:** 11 nÃ¶ron (State verileri).
- **Hidden Layer:** 256 nÃ¶ronluk yoÄŸun bir katman.
- **Output Layer:** 3 nÃ¶ron (DÃ¼z git, Sola dÃ¶n, SaÄŸa dÃ¶n).

#### 3. Ã–dÃ¼l Sistemi (Reward Engineering)
AjanÄ± eÄŸitmek iÃ§in ÅŸu "havuÃ§-sopa" yÃ¶ntemini kullandÄ±m:
- **Yemek Yeme:** +10 puan (Aferin, doÄŸru yoldasÄ±n!)
- **Ã–lÃ¼m (Duvara/KuyruÄŸa Ã‡arpma):** -10 puan (Bunu bir daha yapma!)
- **GeÃ§en SÃ¼re:** 0 puan (AmaÃ§ en kÄ±sa sÃ¼rede yemeÄŸe ulaÅŸmak).

### ğŸ EÄŸitim SÃ¼reci NasÄ±l Ä°lerliyor?

YÄ±lan ilk baÅŸladÄ±ÄŸÄ±nda tamamen bir "bebek" gibidir; saÄŸa sola rastgele Ã§arpar. Ancak **Exploration vs. Exploitation** (KeÅŸfetme ve Faydalanma) dengesi sayesinde zamanla tecrÃ¼be kazanÄ±r:
- **Epsilon:** BaÅŸlarda yÃ¼ksek tutulur ki yÄ±lan dÃ¼nyayÄ± keÅŸfetsin.
- **Memory (Deneyim TekrarÄ±):** GeÃ§miÅŸteki hamlelerini hatÄ±rlar ve bu deneyimlerden rastgele Ã¶rnekler Ã§ekerek Ã¶ÄŸrenmesini pekiÅŸtirir.

BirkaÃ§ yÃ¼z oyun sonunda yÄ±lanÄ±n elmayÄ± gÃ¶rdÃ¼ÄŸÃ¼ anda saniyeler iÃ§inde hedefe kitlenmesini ve kendi gÃ¶vdesine Ã§arpmamak iÃ§in yaptÄ±ÄŸÄ± kÄ±vrak manevralarÄ± izlemek gerÃ§ekten bÃ¼yÃ¼leyici.

### ğŸš€ Teknik Kurulum ve Kaynak Kodlar

Projenin tÃ¼m kodlarÄ± aÃ§Ä±k kaynak olarak GitHub'da mevcut. Kendi makinenizde eÄŸitmek veya canlÄ± izlemek iÃ§in:

ğŸ‘‰ [SnakeAI GitHub Deposu](https://github.com/gevezeus/SnakeAI)

**Gerekli KÃ¼tÃ¼phaneler:**
- `Pygame`: GÃ¶rselleÅŸtirme iÃ§in.
- `PyTorch`: Sinir aÄŸÄ±nÄ± eÄŸitmek iÃ§in.
- `Numpy`: Matematiksel hesaplamalar iÃ§in.

```bash
# Kurulum
pip install pygame torch numpy

# BaÅŸlatma
python agent.py
```

Bu proje, yapay zekanÄ±n "deneme-yanÄ±lma" yoluyla ne kadar kompleks problemleri Ã§Ã¶zebileceÄŸinin kÃ¼Ã§Ã¼k ama etkili bir kanÄ±tÄ±dÄ±r. Gelecekte bu modeli daha karmaÅŸÄ±k oyunlar veya gerÃ§ek dÃ¼nya senaryolarÄ± iÃ§in geliÅŸtirmeyi planlÄ±yorum.

SorularÄ±nÄ±z ve katkÄ±larÄ±nÄ±z iÃ§in GitHub Ã¼zerinden bir Issue aÃ§abilir veya yorumlarda belirtebilirsiniz!

âš¡ **Turgut ÅimÅŸek**
